<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>chmod +x singularity.sh</title><link>http://bt3gl.github.io/</link><description></description><atom:link href="http://bt3gl.github.io/feeds/ai-ml-review.rss.xml" rel="self"></atom:link><lastBuildDate>Sat, 06 Aug 2016 00:00:00 -0400</lastBuildDate><item><title>ICYM AI &amp; ML - Week #31 of 2016</title><link>http://bt3gl.github.io/icym-ai-ml-week-31-of-2016.html</link><description>&lt;h2&gt;Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.blackhat.com/docs/us-16/materials/us-16-Wolff-Applied-Machine-Learning-For-Data-Exfil-And-Other-Fun-Topics.pdf"&gt;Black Hat 2016: Applied Machine Learning for Data Exfil and Other Fun Topics&lt;/a&gt;. Cylance's researchers show some examples of how they apply K-means, Decision Trees, and Markov Chains to security's problems.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.blackhat.com/docs/us-16/materials/us-16-Berlin-An-AI-Approach-To-Malware-Similarity-Analysis-Mapping-The-Malware-Genome-With-A-Deep-Neural-Network.pdf"&gt;Black Hat 2016: An AI approach to Malware Similarity Analysis&lt;/a&gt;Invincea Lab's Researcher shows how they use supervised learning approaches to extract features in Malware data.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=T1O3ikmTEdA&amp;amp;feature=youtu.be&amp;amp;t=10m56s"&gt;Peter Norvig: How Computers Learn&lt;/a&gt;. Great introduction and review of AI and ML's history.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Articles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://aiimpacts.org/costs-of-extinction-risk-mitigation/"&gt;Costs of extinction risk mitigation&lt;/a&gt;. A Cost-Benefit Analysis of the extinction risk mitigation, claiming that the annual cost of reducing the probability of human extinction by 0.01% is within the range of $1.1 billion to $3.5 trillion. &lt;/li&gt;
&lt;li&gt;&lt;a href="http://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html"&gt;Written Memories: Understanding, Deriving and Extending the LSTM&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://medium.com/technologymadeeasy/the-best-explanation-of-convolutional-neural-networks-on-the-internet-fbb8b1ad5df8#.4on1g3268"&gt;(Self-titled) The best explanation of Convolutional Neural Networks on the Internet&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://nuit-blanche.blogspot.com/2016/08/secure-group-testing.html"&gt;Secure Group Testing&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.theverge.com/2016/7/13/12172904/facebook-ai-big-sur-machine-learning-prineville-data-center"&gt;Exploring Facebookâ€™s massive, picture-painting AI brain&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://code.facebook.com/posts/1687861518126048/facebook-to-open-source-ai-hardware-design/?_fb_noscript=1"&gt;Facebook to open-source AI hardware design&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arstechnica.com/science/2016/07/algorithms-used-to-study-brain-activity-may-be-exaggerating-results/"&gt;Software faults raise questions about the validity of brain studies&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://prefrontal.org/files/posters/Bennett-Salmon-2009.pdf"&gt;Neural correlates of interspecies perspective taking in the post-mortem Atlantic Salmon: An argument for multiple comparisons correction&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://sarahjamielewis.com/posts/adversarial-machine-learning.html"&gt;Adversarial Machine Learning for Security&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://deepdrive.io/"&gt;DeepDriveself-driving car AI&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://intelligence.org/2016/08/02/2016-summer-program-recap/"&gt;2016 summer program recap&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.benjamintd.com/blog/spynet/"&gt;Teaching an AI to write Python code with Python code&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1607.08022"&gt;Instance Normalization: The Missing Ingredient for Fast Stylization (Ulyanov, &lt;em&gt;et. al&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.creativeai.net/posts/CjrYHppotnFXbeWW8/learning-semantic-deformation-flows-with-3d-convolutional"&gt;Learning Semantic Deformation Flows with 3D Convolutional Networks &lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Events&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.reddit.com/r/MachineLearning/comments/4v58b2/google_brain_will_be_doing_an_ama_in/"&gt;Google Brain will be doing an AMA in August 11st&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Tools&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://norvig.com/ipython/README.html"&gt;List of IPython (Jupyter) Notebooks by Peter Norvig&lt;/a&gt;.  &lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/cchio/deep-pwning"&gt;Deep Pwning: Metasploit for machine learning&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/jcjohnson/cnn-benchmarks"&gt;Benchmarks for popular CNN models&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Videos&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=GWn7vD2Ud3M"&gt;Build an Autoencoder in 5 Min&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marina von Steinkirch</dc:creator><pubDate>Sat, 06 Aug 2016 00:00:00 -0400</pubDate><guid>tag:bt3gl.github.io,2016-08-06:icym-ai-ml-week-31-of-2016.html</guid></item><item><title>ICYM AI &amp; ML - Week #30 of 2016</title><link>http://bt3gl.github.io/icym-ai-ml-week-30-of-2016.html</link><description>&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf"&gt;ImageNet Classification with Deep Convolutional Neural Networks (Krizhevsky, &lt;em&gt;et al.&lt;/em&gt;, 2014)&lt;/a&gt;. AlexNet.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1409.1556.pdf"&gt;Very Deep Convolutional Networks for large-scale image recognition (Simonyan, &lt;em&gt;et al.&lt;/em&gt;, 2014)&lt;/a&gt;. Image classification.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1207.0580.pdf"&gt;Improving neural networks by preventing co-adaptation of feature detectors&lt;/a&gt;. Dropout and regularization.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1503.03832v3.pdf"&gt;FaceNet: A Unified Embedding for Face Recognition and Clustering (Schroff, &lt;em&gt;et al.&lt;/em&gt;, 2015)&lt;/a&gt;.  Metric learning (FaceNet).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1512.03385v1.pdf"&gt;Deep Residual Learning for Image Recognition (He, &lt;em&gt;et al.&lt;/em&gt;, 2015)&lt;/a&gt;. Very deep networks (ResNet).&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1409.0473v7.pdf"&gt;Neural Machine Translation by jointly learning to align and translate (Bahdanau, &lt;em&gt;et al.&lt;/em&gt;, 2015)&lt;/a&gt;. RNNs, LSTMs, GRUs - machine translation with alignment.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1412.5903v5.pdf"&gt;Deep structured output learning for unconstrained text recognition (Jaderberg,  &lt;em&gt;et al.&lt;/em&gt;, 2014)&lt;/a&gt;.  Text recognition.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/pdf/1512.02595v1.pdf"&gt;Deep Speech 2: End-to-End Speech Recognition in English and Mandarin (Amodei,  &lt;em&gt;et al.&lt;/em&gt;, 2015)&lt;/a&gt;. Speech recognition (DeepSpeech 2).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1508.06576v2.pdf"&gt;A Neural Algorithm of Artistic Style (Gatys,  &lt;em&gt;et al.&lt;/em&gt;, 2015)&lt;/a&gt;. Artistic style transfer.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1511.08228v3.pdf"&gt;Neural GPUs learn algorithms (Kaiser, &lt;em&gt;et al.&lt;/em&gt;, 2015)&lt;/a&gt;. A Neural GPUs.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://people.csail.mit.edu/kalyan/AI2_Paper.pdf"&gt;AI2: Training a big data machine to defend (Kalyan, &lt;em&gt;et al.&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://download.tensorflow.org/paper/whitepaper2015.pdf"&gt;Tensor Flow Whitepaper, (Abadi, &lt;em&gt;et al.&lt;/em&gt;, 2014)&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://lvdmaaten.github.io/publications/papers/Torchnet_2016.pdf"&gt;Torchnet: An Open-Source Platform for (Deep) Learning Research, (Collobert, &lt;em&gt;et al.&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Interesting to see the relation between 1998's LeCun 10^6 transistors and 10^7 pixels in training and then 2012's Krizhevsky 10^9 transistors (and GPU) and 10^14 pixels in training.&lt;/p&gt;
&lt;h2&gt;Articles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://yanpanlau.github.io/2016/07/10/FlappyBird-Keras.html"&gt;Using Keras and Deep Q-Network to Play FlappyBird&lt;/a&gt;. Hands-on on Google DeepMind's Deep Q-Network.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/"&gt;Neural Networks, Manifolds, and Topology&lt;/a&gt;. This is a 2-years-old article, but a very well-written high-level explanation of the topology of low-dimensional NNs. "&lt;em&gt;The task of a classification algorithm is fundamentally to separate a bunch of tangled manifolds.&lt;/em&gt;"&lt;/li&gt;
&lt;li&gt;&lt;a href="http://colah.github.io/posts/2015-08-Backprop/"&gt;Calculus on Computational Graphs: Backpropagation&lt;/a&gt;. Backpropagation explaned in a very well-written text.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;Understanding LSTM Networks&lt;/a&gt;. Another hit :).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://colah.github.io/posts/2015-01-Visualizing-Representations/"&gt;Visualizing Representations: Deep Learning and Human Beings.&lt;/a&gt; Another Christopher Olah's great post, now on NN's different layers representations, tanging some philosophic aspects of it.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cs.stanford.edu/people/karpathy/cnnembed/"&gt;Karpathy's t-SNE visualization of CNN codes.&lt;/a&gt; He takes the 50k ILSVRC 2012 validation images, extracts the 4096-dimensional fc7 CNN features using Caffe and then uses Barnes-Hut t-SNE to compute a 2-dimensional embedding that respects the high-dimensional (L2) distances. &lt;/li&gt;
&lt;li&gt;&lt;a href="https://blogs.nvidia.com/blog/2016/01/12/accelerating-ai-artificial-intelligence-gpus/"&gt;NVIDIA's Accelerating AI with GPUs: A New Computing Model&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://code.facebook.com/posts/580706092103929/lighting-the-way-to-deep-machine-learning/"&gt;Torchnet: Lighting the way to deep machine learning&lt;/a&gt;. "&lt;em&gt;&lt;a href="https://github.com/torchnet/torchnet"&gt;Torchnet&lt;/a&gt; is different from frameworks such as Caffe, Chainer, TensorFlow, and Theano, in that it does not focus on performing efficient inference and gradient computations in deep networks. Instead, Torchnet provides a framework on top of a deep learning framework that makes rapid experimentation easier.&lt;/em&gt;"&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/44921.pdf"&gt;Large-Scale Deep Learning for Intelligent Computer Systems by Jeff Dean&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Tools&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://cloud.google.com/blog/big-data/2016/07/understanding-neural-networks-with-tensorflow-playground"&gt;Understanding neural networks with TensorFlow Playground&lt;/a&gt;.  &lt;/li&gt;
&lt;li&gt;&lt;a href="http://cs.stanford.edu/people/karpathy/convnetjs//demo/classify2d.html"&gt;Karpathy's ConvNetJS viz tool.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Videos&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=JeBkUtYvBBM"&gt;Prof. Adrian Owen on The Search for Consciousness: detecting awareness in the vegetative state (2015)&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&amp;lt;3&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=Ics9CjRSMfc"&gt;Baidu AI Composer&lt;/a&gt;. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Remember that the hidden layer learns a representation so that the data is linearly separable, so that's is how you do separate a spiral two-dimensional dataset using Tensorflow playground and Convnetjs:&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With tanh:&lt;/p&gt;
&lt;p&gt;&lt;img alt="tahn2" height="300px" src="./tensor_flow_playground/tanh2.png" width="400px" /&gt;  &lt;img alt="tahn11" height="300px" src="./tensor_flow_playground/tan1.png" width="400px" /&gt;   &lt;img alt="tan2" height="300px" src="./tensor_flow_playground/tan2.png" width="400px" /&gt;   &lt;img alt="tan3" height="300px" src="./tensor_flow_playground/tan3.png" width="400px" /&gt; &lt;/p&gt;
&lt;p&gt;With ReLU:&lt;/p&gt;
&lt;p&gt;&lt;img alt="relu2" height="300px" src="./tensor_flow_playground/relu2.png" width="400px" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;That's is how you do not separate a spiral two-dimensional dataset:&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="linear" height="300px" src="./tensor_flow_playground/linear.png" width="400px" /&gt; &lt;img alt="relu_no" height="300px" src="./tensor_flow_playground/relu_no.png" width="400px" /&gt; &lt;img alt="sigmoid" height="300px" src="./tensor_flow_playground/sigmoid.png" width="400px" /&gt;  &lt;img alt="relu_no2" height="300px" src="./tensor_flow_playground/relu_no2.png" width="400px" /&gt;  &lt;img alt="relu_no3" height="300px" src="./tensor_flow_playground/relu_no3.png" width="400px" /&gt;  &lt;img alt="relu_no4" height="300px" src="./tensor_flow_playground/relu_no4.png" width="400px" /&gt; &lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marina von Steinkirch</dc:creator><pubDate>Sat, 30 Jul 2016 00:00:00 -0400</pubDate><guid>tag:bt3gl.github.io,2016-07-30:icym-ai-ml-week-30-of-2016.html</guid></item><item><title>ICYM AI &amp; ML - Week #29 of 2016</title><link>http://bt3gl.github.io/icym-ai-ml-week-29-of-2016.html</link><description>&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://arxiv.org/pdf/1409.4842.pdf"&gt;Going deeper with Convolutions (Szegedy, &lt;em&gt;et al.&lt;/em&gt;, 2014)&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=yxxRAHVtafI"&gt;The Science of Talking with Computers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=NK6O8CtI2D4"&gt;Megan Smith: Perspectives on artificial intelligence from the White House&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=6eBpjEdgSm0"&gt;NVIDIA Deep Learning Course: Class #1 â€“ Introduction to Deep Learning&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&amp;lt;3&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=u2t77mQmJiY"&gt;A genetic algorithm learns how to fight!&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marina von Steinkirch</dc:creator><pubDate>Sat, 23 Jul 2016 00:00:00 -0400</pubDate><guid>tag:bt3gl.github.io,2016-07-23:icym-ai-ml-week-29-of-2016.html</guid></item><item><title>ICYM AI &amp; ML - Week #28 of 2016</title><link>http://bt3gl.github.io/icym-ai-ml-week-28-of-2016.html</link><description>&lt;h2&gt;Articles&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.benjamintd.com/blog/spynet/?utm_campaign=Artificial%2BIntelligence%2BWeekly&amp;amp;utm_medium=web&amp;amp;utm_source=Artificial_Intelligence_Weekly_42"&gt;Teaching an AI to write Python code with Python code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/"&gt;Understanding LSTM Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://efavdb.com/deep-learning-with-jupyter-on-aws/"&gt;Starting DL with Jupyter&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.google.com/presentation/d/1UeKXVgRvvxg9OUdh_UiC5G71UMscNPlvArsWER41PsU/edit#slide=id.gc2fcdcce7_216_515"&gt;DIY Deep Learning for Vision:  a Hands-On Tutorial with Caffe&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://research.googleblog.com/2016/06/wide-deep-learning-better-together-with.html"&gt;Wide &amp;amp; Deep Learning: Better Together with TensorFlow&lt;/a&gt;. &lt;em&gt;Can we teach computers to learn like humans do, by combining the power of memorization and generalization?&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Papers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://gogameguru.com/i/2016/03/deepmind-mastering-go.pdf"&gt;Mastering the Game of Go with Deep Neural Networks and Tree Search&lt;/a&gt;. Basically:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Values networks to evaluate board positions and policy networks to select moves.&lt;/li&gt;
&lt;li&gt;Trained with supervised learning from human expert games and reinforcement learning from games of self-play.&lt;/li&gt;
&lt;li&gt;NN playS Go at the level of state-of-art Monte-Carlo tree search that simulate thousands of random games of self-play.&lt;/li&gt;
&lt;li&gt;New search algorithm that combines Monte-Carlo simulation with value and policy network.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/pdf/1607.02533v1.pdf"&gt;Adversarial Examples in the Physical World (Kurakin, &lt;em&gt;et al.&lt;/em&gt;, 2016)&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Talks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://icml.cc/2016/tutorials/icml2016_tutorial_deep_residual_networks_kaiminghe.pdf"&gt;Deep Residual Networks, Kaiming He, Facebook AI Research&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Resources_files/AlphaGo_IJCAI.pdf"&gt;AlphaGo Presentation&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=XkltShNd6XE"&gt;Prof. JÃ¼rgen Schmidhuber - True Artificial Intelligence Will Change Everything&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&amp;lt;3&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;"All games of perfect information have an optimal value function which determines the outcome of the game".&lt;/em&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://diogenes.greedbag.com/buy/ghost-lanes-0/"&gt;Post-Rock as it best: Ghost Lanes&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Marina von Steinkirch</dc:creator><pubDate>Sat, 16 Jul 2016 00:00:00 -0400</pubDate><guid>tag:bt3gl.github.io,2016-07-16:icym-ai-ml-week-28-of-2016.html</guid></item></channel></rss>